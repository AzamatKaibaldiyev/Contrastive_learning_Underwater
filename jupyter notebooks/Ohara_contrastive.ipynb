{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f34fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Number of workers: 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = 1\n",
    "\n",
    "\n",
    "## Standard libraries\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('viridis')\n",
    "%matplotlib inline\n",
    "#from IPython.display import set_matplotlib_formats\n",
    "#set_matplotlib_formats('svg', 'pdf') # For export\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 0 #2.0\n",
    "#import seaborn as sns\n",
    "#sns.set()\n",
    "\n",
    "## tqdm for loading bars\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "## Torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "#try:\n",
    "#    import pytorch_lightning as pl\n",
    "#except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "#    !pip install --quiet pytorch-lightning>=1.4\n",
    "#    import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "# Import tensorboard\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "#DATASET_PATH = \"../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = '/home/azamat.kaibaldiyev/Tasmania_ohara_labels/checkpoints_dems_32/'\n",
    "\n",
    "# In this notebook, we use data loaders with heavier computational processing. It is recommended to use as many\n",
    "# workers as possible in a data loader, which corresponds to the number of CPU cores\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Number of workers:\", NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dbaf1182",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "rs = ShuffleSplit(n_splits=1, test_size=.1, random_state=0)\n",
    "for i, (train_index, test_index) in enumerate(rs.split(dataset)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "646cfeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('files_remove_indices/Ohara_train_set_indexes.npy', 'wb') as f:\n",
    "#    np.save(f, train_index)\n",
    "\n",
    "#with open('files_remove_indices/Ohara_test_set_indexes.npy', 'wb') as f:\n",
    "#    np.save(f, test_index)\n",
    "\n",
    "with open('files_remove_indices/Ohara_train_set_indexes.npy', 'rb') as f:\n",
    "    train_set_indexes = np.load(f)\n",
    "\n",
    "with open('files_remove_indices/Ohara_test_set_indexes.npy', 'rb') as f:\n",
    "    test_set_indexes = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "253e01df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100652\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_set_indexes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 92\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset))\n\u001b[1;32m     90\u001b[0m dataset_len \u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataset)\n\u001b[0;32m---> 92\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mSubset(dataset, \u001b[43mtrain_set_indexes\u001b[49m)\n\u001b[1;32m     93\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mSubset(dataset, test_set_indexes)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_dataset))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set_indexes' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import rasterio\n",
    "dataset_path = 'Tasmania_ohara_labels/cropped_dems_32/'\n",
    "dataset_path_with_labels = 'Tasmania_ohara_labels/cropped_dems_32_with_labels/'\n",
    "\n",
    "class SwedishDataset(Dataset):\n",
    "    def __init__(self,  transform  = None, dataset_path = None, remove_list = None):\n",
    "        self.imgs_path = dataset_path\n",
    "        self.file_list_dem = sorted(glob.glob(self.imgs_path + \"*\"))\n",
    "\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list_dem)\n",
    "\n",
    "          \n",
    "    def __getitem__(self, idx):\n",
    "        img_path_dem = self.file_list_dem[idx]\n",
    "        img_raster_dem = rasterio.open(img_path_dem).read()\n",
    "        if self.imgs_path==dataset_path_with_labels:\n",
    "            label = int(self.file_list_dem[idx][-6])\n",
    "        else:\n",
    "            label = 'no_label'\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            img_raster_dem = self.transform(torch.tensor(img_raster_dem))\n",
    "        \n",
    "        \n",
    "        return [img_raster_dem, label]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def normalize_input_for_dem(test_iter):\n",
    "    #test_iter = torch.from_numpy(test_iter)\n",
    "    input_images = test_iter.float()\n",
    "    #maxv = 822\n",
    "    #minv = -37\n",
    "    batch_size = input_images.shape[0]\n",
    "    cmin = torch.amin(input_images,(1,2)).reshape((batch_size,1,1))\n",
    "    cmax = torch.amax(input_images,(1,2)).reshape((batch_size,1,1))\n",
    "    return (input_images-cmin)/(cmax-cmin) #(input_images-minv)/(maxv-minv) #(input_images-cmin)/(cmax-cmin)\n",
    "\n",
    "class Normalize_range01:\n",
    "    #bring to range 0 to 1\n",
    "\n",
    "    def __init__(self, p=1):\n",
    "        self.p = 1\n",
    "\n",
    "    def __call__(self, x):\n",
    "        result = normalize_input_for_dem(x)\n",
    "        return result\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"custom augmentation\"\n",
    "    \n",
    "class ContrastiveTransformations(object):\n",
    "\n",
    "    def __init__(self, base_transforms, n_views=2):\n",
    "        self.base_transforms = base_transforms\n",
    "        self.n_views = n_views\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return [self.base_transforms(x) for i in range(self.n_views)]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "contrast_transforms = transforms.Compose([#transforms.ToTensor(),\n",
    "                                          #transforms.Resize(size = img_size),\n",
    "                                          #Normalize_range01(),\n",
    "                                          #transforms.ToPILImage(), \n",
    "                                          #transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomResizedCrop(size=32),\n",
    "                                          #transforms.RandomApply([transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1)], p=0.8),\n",
    "                                          #transforms.RandomGrayscale(p=0.2),\n",
    "                                          #transforms.GaussianBlur(kernel_size=9),\n",
    "                                          #transforms.ToTensor(),\n",
    "                                          transforms.Normalize((0.5,), (0.5,))\n",
    "                                         ])\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "import math\n",
    "dataset = SwedishDataset(transform = ContrastiveTransformations(contrast_transforms, n_views = 2), dataset_path = dataset_path)\n",
    "\n",
    "print(len(dataset))\n",
    "dataset_len =len(dataset)\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_set_indexes)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_set_indexes)\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "#print(dataset[4][0][0].shape)\n",
    "#dataset[4][1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f57770e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azamat.kaibaldiyev/miniconda3/envs/contrastive_env/lib/python3.10/site-packages/rasterio/__init__.py:220: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix be returned.\n",
      "  s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "/home/azamat.kaibaldiyev/miniconda3/envs/contrastive_env/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c810faf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[29.4740, 29.4760, 29.5720,  ..., 28.0480, 27.8200, 27.7920],\n",
       "         [29.5139, 29.5956, 29.6173,  ..., 28.4214, 28.2894, 27.9479],\n",
       "         [29.5821, 29.6704, 29.7064,  ..., 28.5123, 28.2840, 28.2121],\n",
       "         ...,\n",
       "         [31.1225, 31.2100, 31.2837,  ..., 33.1899, 33.2636, 33.3464],\n",
       "         [31.2001, 31.2231, 31.3098,  ..., 33.2231, 33.2759, 33.3708],\n",
       "         [31.2980, 31.3500, 31.3660,  ..., 33.2340, 33.3140, 33.3780]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b63d012",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6cc60cd",
   "metadata": {},
   "source": [
    "!wandb login --relogin \"40706c6c21e200af3bdb3840883f22e665e74441\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "46f37b04",
   "metadata": {},
   "source": [
    "import wandb\n",
    "import random\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "epochs = 300\n",
    "lr = 1e-5\n",
    "#wandb.init(settings=wandb.Settings(start_method=\"fork\"))\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"Contrastive_SimCLR_Ohara\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": lr,\n",
    "    \"architecture\": \"SimCLR\",\n",
    "    \"dataset\": \"Ohara_dataset_32\",\n",
    "    \"epochs\": epochs,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a3781b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=500):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        assert self.hparams.temperature > 0.0, 'The temperature must be a positive float!'\n",
    "        # Base model f(.)\n",
    "        self.convnet = torchvision.models.resnet18(num_classes=4*hidden_dim)  # Output of last linear layer\n",
    "        #model = torchvision.models.resnet18()\n",
    "        num_input_channel = 1\n",
    "        self.convnet.conv1 = nn.Conv2d(num_input_channel, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "        # The MLP for g(.) consists of Linear->ReLU->Linear\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            self.convnet.fc,  # Linear(ResNet output, 4*hidden_dim)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4*hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(),\n",
    "                                lr=self.hparams.lr,\n",
    "                                weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                            T_max=self.hparams.max_epochs,\n",
    "                                                            eta_min=self.hparams.lr/50)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def info_nce_loss(self, batch, mode='train'):\n",
    "        imgs, _ = batch\n",
    "        imgs = torch.cat(imgs, dim=0)\n",
    "\n",
    "        # Encode all images\n",
    "        feats = self.convnet(imgs)\n",
    "        # Calculate cosine similarity\n",
    "        cos_sim = F.cosine_similarity(feats[:,None,:], feats[None,:,:], dim=-1)\n",
    "        # Mask out cosine similarity to itself\n",
    "        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "        cos_sim.masked_fill_(self_mask, -9e15)\n",
    "        # Find positive example -> batch_size//2 away from the original example\n",
    "        pos_mask = self_mask.roll(shifts=cos_sim.shape[0]//2, dims=0)\n",
    "        # InfoNCE loss\n",
    "        cos_sim = cos_sim / self.hparams.temperature\n",
    "        nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "        nll = nll.mean()\n",
    "\n",
    "        # Logging loss\n",
    "        self.log(mode+'_loss', nll)\n",
    "        wandb.log({'SimCLR_'+mode+'_loss':nll})\n",
    "        # Get ranking position of positive example\n",
    "        comb_sim = torch.cat([cos_sim[pos_mask][:,None],  # First position positive example\n",
    "                              cos_sim.masked_fill(pos_mask, -9e15)],\n",
    "                             dim=-1)\n",
    "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "        # Logging ranking metrics\n",
    "        wandb.log({'SimCLR_'+mode+'_acc_top1':(sim_argsort == 0).float().mean()})\n",
    "        wandb.log({'SimCLR_'+mode+'_acc_top5':(sim_argsort < 5).float().mean()})\n",
    "        wandb.log({'SimCLR_'+mode+'_acc_mean_pos': 1+sim_argsort.float().mean()})\n",
    "        \n",
    "        self.log(mode+'_acc_top1', (sim_argsort == 0).float().mean())\n",
    "        self.log(mode+'_acc_top5', (sim_argsort < 5).float().mean())\n",
    "        self.log(mode+'_acc_mean_pos', 1+sim_argsort.float().mean())\n",
    "\n",
    "        return nll\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.info_nce_loss(batch, mode='train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.info_nce_loss(batch, mode='val')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.convnet(x)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bc27b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simclr(batch_size, max_epochs=500, **kwargs):\n",
    "    trainer = pl.Trainer(log_every_n_steps=10, default_root_dir=os.path.join(CHECKPOINT_PATH, 'SimCLR'),\n",
    "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices=1,\n",
    "                         max_epochs=max_epochs,\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode='max', monitor='val_acc_top5'),\n",
    "                                    LearningRateMonitor('epoch')])\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, 'SimCLR.ckpt')\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f'Found pretrained model at {pretrained_filename}, loading...')\n",
    "        model = SimCLR.load_from_checkpoint(pretrained_filename) # Automatically loads the model with the saved hyperparameters\n",
    "    else:\n",
    "        train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                       drop_last=True, pin_memory=True, num_workers=2)\n",
    "        val_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                     drop_last=False, pin_memory=True, num_workers=2)\n",
    "        pl.seed_everything(42) # To be reproducable\n",
    "        model = SimCLR(max_epochs=max_epochs, **kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        model = SimCLR.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "764e801f",
   "metadata": {},
   "source": [
    "simclr_model = train_simclr(batch_size=256,\n",
    "                            hidden_dim=128,\n",
    "                            lr=5e-4,\n",
    "                            temperature=0.07,\n",
    "                            weight_decay=1e-4,\n",
    "                            max_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de77727",
   "metadata": {},
   "source": [
    "# Downstream Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "914260b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/azamat.kaibaldiyev/.netrc\r\n"
     ]
    }
   ],
   "source": [
    "!wandb login --relogin \"40706c6c21e200af3bdb3840883f22e665e74441\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25d2f4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:7o6o7tzb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Downstream_test_acc</td><td>▅▅█▆▃▄▃▅█▅▄▃▂▆▅▄▅▃▅▆▅▄▆▃▅▃▆▅▅▃▅▃▃▃▄▃▄▁▄▂</td></tr><tr><td>Downstream_test_learningrate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Downstream_test_loss</td><td>▃▄▁▂▅▅▆▅▃▄▅▄▇▃▄▃▄▆▄▄▄▆▄▇▄▇▄▅▅▇▄▅█▇▆▇▅▇▆▇</td></tr><tr><td>Downstream_train_acc</td><td>▁▆▄▅▅▅▆▆▅▆▅▇▆▅▅█▅▇▆▇▆▆▇▆▄▅▇▅▅▇▇▇▆▇▇▇▇▆▆▅</td></tr><tr><td>Downstream_train_learningrate</td><td>████████████████████████████████████▁▁▁▁</td></tr><tr><td>Downstream_train_loss</td><td>█▅▄▃▃▃▃▃▃▂▃▃▂▃▃▁▂▂▂▂▂▂▂▂▄▂▁▃▃▁▁▁▂▁▁▂▁▂▂▃</td></tr><tr><td>Downstream_val_acc</td><td>▂▇▅▂▇▂▅▁▇█▅▅▆▁▇▁▇█▅▅▆▁▅▁▇▇▅▅▆▃▅▁▇▇▅▅▅▃▅▃</td></tr><tr><td>Downstream_val_learningrate</td><td>██████████████████████████████████▁▁▁▁▁▁</td></tr><tr><td>Downstream_val_loss</td><td>█▇▆▅▂▆▃▆▂▃▄▄▁▅▂▅▂▂▄▃▁▅▅▄▁▁▃▃▁▅▄▄▁▁▃▃▂▅▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Downstream_test_acc</td><td>0.80435</td></tr><tr><td>Downstream_test_learningrate</td><td>0.0</td></tr><tr><td>Downstream_test_loss</td><td>0.57418</td></tr><tr><td>Downstream_train_acc</td><td>0.73171</td></tr><tr><td>Downstream_train_learningrate</td><td>0.0</td></tr><tr><td>Downstream_train_loss</td><td>0.5937</td></tr><tr><td>Downstream_val_acc</td><td>0.80435</td></tr><tr><td>Downstream_val_learningrate</td><td>0.0</td></tr><tr><td>Downstream_val_loss</td><td>0.57402</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">curious-resonance-65</strong> at: <a href='https://wandb.ai/self-sup-segm/Contrastive_SimCLR_Ohara/runs/7o6o7tzb' target=\"_blank\">https://wandb.ai/self-sup-segm/Contrastive_SimCLR_Ohara/runs/7o6o7tzb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230523_233212-7o6o7tzb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:7o6o7tzb). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49f7c86a8394c4599190196d6710949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668424031619604, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/baie/nfs-cluster-1/data2/home/azamat.kaibaldiyev/wandb/run-20230523_234342-heyuxted</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/self-sup-segm/Contrastive_SimCLR_Ohara/runs/heyuxted' target=\"_blank\">genial-galaxy-66</a></strong> to <a href='https://wandb.ai/self-sup-segm/Contrastive_SimCLR_Ohara' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/self-sup-segm/Contrastive_SimCLR_Ohara' target=\"_blank\">https://wandb.ai/self-sup-segm/Contrastive_SimCLR_Ohara</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/self-sup-segm/Contrastive_SimCLR_Ohara/runs/heyuxted' target=\"_blank\">https://wandb.ai/self-sup-segm/Contrastive_SimCLR_Ohara/runs/heyuxted</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/self-sup-segm/Contrastive_SimCLR_Ohara/runs/heyuxted?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fee674485b0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "epochs = 300\n",
    "lr = 1e-5\n",
    "#wandb.init(settings=wandb.Settings(start_method=\"fork\"))\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"Contrastive_SimCLR_Ohara\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": lr,\n",
    "    \"architecture\": \"Downstream_Logreg\",\n",
    "    \"dataset\": \"Ohara_dataset_32\",\n",
    "    \"epochs\": epochs,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "05a949a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, feature_dim, num_classes, lr, weight_decay, max_epochs=300):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # Mapping from representation h to classes\n",
    "        #self.model = nn.Linear(feature_dim, num_classes)\n",
    "        self.model = nn.Sequential(\n",
    "                        nn.Linear(feature_dim, num_classes),\n",
    "                      )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(),\n",
    "                                lr=self.hparams.lr,\n",
    "                                weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                      milestones=[int(self.hparams.max_epochs*0.6),\n",
    "                                                                  int(self.hparams.max_epochs*0.8)],\n",
    "                                                      gamma=0.1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def _calculate_loss(self, batch, mode='train'):\n",
    "        #criterion = F.cross_entropy()\n",
    "        \n",
    "        feats, labels = batch\n",
    "        preds = self.model(feats)\n",
    "        #print('preds', preds)\n",
    "        #print('labels:', labels)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "        wandb.log({'Downstream_' + mode+'_loss': loss})\n",
    "        wandb.log({'Downstream_' + mode+'_acc': acc})\n",
    "        \n",
    "        lightning_optimizer = self.optimizers()  # self = your model\n",
    "        current_lr = lightning_optimizer.optimizer.param_groups[0]['lr']\n",
    "        wandb.log({'Downstream_' + mode+'_learningrate': current_lr})\n",
    "\n",
    "        self.log(mode + '_loss', loss)\n",
    "        self.log(mode + '_acc', acc)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._calculate_loss(batch, mode='train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._calculate_loss(batch, mode='val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._calculate_loss(batch, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ac59279",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('files_remove_indices/Ohara_labels_train_set_indexes.npy', 'rb') as f:\n",
    "    train_set_indexes_labels = np.load(f)\n",
    "\n",
    "with open('files_remove_indices/Ohara_labels_test_set_indexes.npy', 'rb') as f:\n",
    "    test_set_indexes_labels = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "461c6c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10967\n",
      "Number of training examples: 9321\n",
      "Number of test examples: 1646\n"
     ]
    }
   ],
   "source": [
    "img_transforms = transforms.Compose([#Normalize_range01(),\n",
    "                                     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "#dataset_path_with_labels ='Tasmania_ohara_labels/cropped_dems_16_with_labels_correct/'\n",
    "dataset_path_with_labels = 'Tasmania_ohara_labels/cropped_dems_32_with_labels/'\n",
    "\n",
    "dataset = SwedishDataset(transform = img_transforms , dataset_path=dataset_path_with_labels)\n",
    "# #For random split\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_set_indexes_labels)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_set_indexes_labels)\n",
    "\n",
    "#For different lines\n",
    "# dim = 4460\n",
    "# train_dataset = torch.utils.data.Subset(dataset, np.arange(dim))\n",
    "# test_dataset = torch.utils.data.Subset(dataset, np.arange(dim, len(dataset)))\n",
    "\n",
    "print(len(dataset))\n",
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of test examples:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30cca8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_data_features(model, dataset):\n",
    "    # Prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Encode all images\n",
    "    data_loader = data.DataLoader(dataset, batch_size=32, num_workers=NUM_WORKERS, shuffle=False, drop_last=False)\n",
    "    feats, labels = [], []\n",
    "    for batch_imgs, batch_labels in tqdm(data_loader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "\n",
    "    # Sort images by labels\n",
    "    #labels, idxs = labels.sort()\n",
    "    #feats = feats[idxs]\n",
    "    #mycode\n",
    "    feats = torch.squeeze(feats)\n",
    "    labels = torch.squeeze(labels)\n",
    "\n",
    "    return data.TensorDataset(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37a517c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=500):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        assert self.hparams.temperature > 0.0, 'The temperature must be a positive float!'\n",
    "        # Base model f(.)\n",
    "        self.convnet = torchvision.models.resnet18(num_classes=4*hidden_dim)  # Output of last linear layer\n",
    "        #model = torchvision.models.resnet18()\n",
    "        num_input_channel = 1\n",
    "        self.convnet.conv1 = nn.Conv2d(num_input_channel, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "        # The MLP for g(.) consists of Linear->ReLU->Linear\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            self.convnet.fc,  # Linear(ResNet output, 4*hidden_dim)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4*hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(),\n",
    "                                lr=self.hparams.lr,\n",
    "                                weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                            T_max=self.hparams.max_epochs,\n",
    "                                                            eta_min=self.hparams.lr/50)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def info_nce_loss(self, batch, mode='train'):\n",
    "        imgs, _ = batch\n",
    "        imgs = torch.cat(imgs, dim=0)\n",
    "\n",
    "        # Encode all images\n",
    "        feats = self.convnet(imgs)\n",
    "        # Calculate cosine similarity\n",
    "        cos_sim = F.cosine_similarity(feats[:,None,:], feats[None,:,:], dim=-1)\n",
    "        # Mask out cosine similarity to itself\n",
    "        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "        cos_sim.masked_fill_(self_mask, -9e15)\n",
    "        # Find positive example -> batch_size//2 away from the original example\n",
    "        pos_mask = self_mask.roll(shifts=cos_sim.shape[0]//2, dims=0)\n",
    "        # InfoNCE loss\n",
    "        cos_sim = cos_sim / self.hparams.temperature\n",
    "        nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "        nll = nll.mean()\n",
    "\n",
    "        # Logging loss\n",
    "        self.log(mode+'_loss', nll)\n",
    "        # Get ranking position of positive example\n",
    "        comb_sim = torch.cat([cos_sim[pos_mask][:,None],  # First position positive example\n",
    "                              cos_sim.masked_fill(pos_mask, -9e15)],\n",
    "                             dim=-1)\n",
    "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "        # Logging ranking metrics\n",
    "     \n",
    "        self.log(mode+'_acc_top1', (sim_argsort == 0).float().mean())\n",
    "        self.log(mode+'_acc_top5', (sim_argsort < 5).float().mean())\n",
    "        self.log(mode+'_acc_mean_pos', 1+sim_argsort.float().mean())\n",
    "\n",
    "        return nll\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.info_nce_loss(batch, mode='train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.info_nce_loss(batch, mode='val')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.convnet(x)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b717dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'epoch=466-step=164851.ckpt'\r\n"
     ]
    }
   ],
   "source": [
    "!ls Tasmania_ohara_labels/checkpoints_dems_16/SimCLR/lightning_logs/version_1344416/checkpoints/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4475717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'epoch=479-step=169440.ckpt'\r\n"
     ]
    }
   ],
   "source": [
    "!ls Tasmania_ohara_labels/checkpoints_dems_32/SimCLR/lightning_logs/version_1344418/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02602701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (convnet): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoint = '/home/azamat.kaibaldiyev/Tasmania_ohara_labels/checkpoints_dems_32/SimCLR/lightning_logs/version_1344418/checkpoints/epoch=479-step=169440.ckpt'\n",
    "\n",
    "simclr_model = SimCLR.load_from_checkpoint(best_checkpoint)\n",
    "\n",
    "# disable randomness, dropout, etc...\n",
    "simclr_model.eval()\n",
    "simclr_model.to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eef3edfc",
   "metadata": {},
   "source": [
    "data_loader = data.DataLoader(test_dataset, batch_size=32, num_workers=NUM_WORKERS, shuffle=False, drop_last=False)\n",
    "print(1)\n",
    "batch_imgss, batch_labelss = next(iter(data_loader))\n",
    "print(2)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3514d7cd",
   "metadata": {},
   "source": [
    "print(batch_imgss.shape)\n",
    "batch_imgss[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5dbcc919",
   "metadata": {},
   "source": [
    "batch_imgss = batch_imgss.to(device)\n",
    "print(3)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30557c07",
   "metadata": {},
   "source": [
    "res = simclr_model(batch_imgss)\n",
    "print(4)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a061a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb7ee76bad344e0b7eb6260a4eb86f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb22fc23b3d47b2bc55c9296bd0070f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_feats_simclr = prepare_data_features(simclr_model, train_dataset)\n",
    "test_feats_simclr = prepare_data_features(simclr_model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6852bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logreg(batch_size, train_feats_data, test_feats_data, model_suffix, max_epochs=200, **kwargs):\n",
    "    trainer = pl.Trainer(log_every_n_steps=10, default_root_dir=os.path.join(CHECKPOINT_PATH, \"LogisticRegression\"),\n",
    "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices=1,\n",
    "                         max_epochs=max_epochs,\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode='max', monitor='val_acc'),\n",
    "                                    LearningRateMonitor(\"epoch\")],\n",
    "                         enable_progress_bar=False,\n",
    "                         check_val_every_n_epoch=10)\n",
    "    trainer.logger._default_hp_metric = None\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = data.DataLoader(train_feats_data, batch_size=batch_size, shuffle=True,\n",
    "                                   drop_last=False, pin_memory=True, num_workers=0)\n",
    "    test_loader = data.DataLoader(test_feats_data, batch_size=batch_size, shuffle=False,\n",
    "                                  drop_last=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"LogisticRegression_{model_suffix}.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        model = LogisticRegression.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything(42)  # To be reproducable\n",
    "        model = LogisticRegression(**kwargs)\n",
    "        trainer.fit(model, train_loader, test_loader)\n",
    "        model = LogisticRegression.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "    # Test best model on train and validation set\n",
    "    train_result = trainer.test(model, train_loader, verbose=False)\n",
    "    test_result = trainer.test(model, test_loader, verbose=False)\n",
    "    result = {\"train\": train_result[0][\"test_acc\"], \"test\": test_result[0][\"test_acc\"]}\n",
    "\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd5d9c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[rank: 0] Global seed set to 42\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 4.1 K \n",
      "-------------------------------------\n",
      "4.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 K     Total params\n",
      "0.016     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "num_imgs_per_label = 200\n",
    "logreg_model, small_set_results = train_logreg(max_epochs=200,batch_size=128,\n",
    "                                    train_feats_data=train_feats_simclr,\n",
    "                                    test_feats_data=test_feats_simclr,\n",
    "                                    model_suffix=num_imgs_per_label,\n",
    "                                    feature_dim=train_feats_simclr.tensors[0].shape[1],\n",
    "                                    num_classes=8,\n",
    "                                    lr=1e-5,\n",
    "                                    weight_decay=1e-3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4661c62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.7721973061561584, 'test': 0.6397725343704224}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size 16, bs 64, 200 epochs, line set\n",
    "small_set_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc8af87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.652242124080658, 'test': 0.5979714393615723}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size 32, bs 64, 200 epochs, line set\n",
    "small_set_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e507c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fe9c023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.7273897528648376, 'test': 0.7290400862693787}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size 16, bs 128, 300 epochs, random set\n",
    "small_set_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "378ee5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.7292135953903198, 'test': 0.7320777773857117}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size 16, bs 64, 300 epochs, random set\n",
    "small_set_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a142514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.7647247910499573, 'test': 0.763669490814209}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size 32, bs 64, 200 epochs, random set\n",
    "small_set_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4d30aa5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.7595751285552979, 'test': 0.7527338862419128}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size 32, bs 128, 100 epochs, random set\n",
    "small_set_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bcb95dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.764832079410553, 'test': 0.7618468999862671}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size 32, bs 128, 100 epochs, random set   #2 (latest)\n",
    "small_set_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb9e883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
